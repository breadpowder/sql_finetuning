# sql_evaluation_library/src/sql_eval_lib/evaluation/exec_evaluator.py
import sqlite3
import json # Not strictly needed for this module's core logic as per design,
            # but can be useful for serializing complex outputs if required later.
            # The design asks for normalized list of string tuples, not JSON strings for output fields.

try:
    from ..langfuse.manager import LangfuseClient # Updated path and class name
except ImportError:
    print("ExecEvaluator: Could not import LangfuseClient from ..langfuse.manager, using a dummy type hint if needed.")
    LangfuseClient = type("LangfuseClient", (object,), {}) # Dummy type for hinting

try:
    from ..utils.helpers import split_sql_statements # Updated path
except ImportError:
    print("ExecEvaluator: Could not import split_sql_statements from ..utils.helpers. Ensure helpers.py exists.")
    # Define a dummy fallback if utils is missing, to allow basic module loading
    def split_sql_statements(sql_context: str) -> list[str]:
        print(f"Warning: Using dummy split_sql_statements for '{sql_context[:50]}...'")
        return [s.strip() for s in sql_context.split(';') if s.strip()]


class ExecutionEvaluationModule:
    """
    Evaluates SQL queries by executing them against an in-memory SQLite database
    and comparing their results.
    """
    def __init__(self, langfuse_manager: LangfuseClient = None): # Updated type hint
        """
        Initializes the Execution Evaluation Module.

        Args:
            langfuse_manager (LangfuseClient, optional): Instance for logging. # Updated type hint
                Defaults to None, in which case logging is skipped.
        """
        self.langfuse_manager = langfuse_manager
        print(f"ExecutionEvaluationModule initialized. Langfuse logging {'enabled' if self.langfuse_manager and self.langfuse_manager.enabled else 'disabled'}.")

    def _normalize_results(self, raw_results: list[tuple]) -> list[tuple[str, ...]]:
        """
        Normalizes raw database results for comparison.
        - Converts all cell values in each row to strings.
        - Sorts the list of rows (represented as tuples) to ensure order-insensitive comparison.
        """
        if not raw_results:
            return []
        
        try:
            # Convert each cell to string, then each row to a tuple of strings
            stringified_rows = [tuple(map(str, row)) for row in raw_results]
            # Sort the list of stringified tuples (rows)
            # Sort by all elements in the tuple to ensure deterministic order
            sorted_stringified_rows = sorted(stringified_rows) 
            return sorted_stringified_rows
        except TypeError as e:
            # This might happen if raw_results contains non-iterable rows or unexpected types
            print(f"Error during result normalization: {e}. Input: {raw_results}")
            # Fallback: convert entire thing to string, or handle more gracefully
            return [tuple(map(str, (str(raw_results),)))] # Represents an error state or unprocessable format


    def evaluate_single_item(self, trace, generated_sql: str, ground_truth_sql: str, sql_context: str) -> dict:
        """
        Evaluates a single item by setting up an in-memory SQLite database,
        executing the generated and ground truth SQL queries, and comparing their results.

        Args:
            trace: The Langfuse trace object (or None if Langfuse is disabled/not used).
            generated_sql (str): The SQL query generated by the model under test.
            ground_truth_sql (str): The reference SQL query.
            sql_context (str): The SQL statements (CREATE TABLE, INSERT INTO) to set up the database schema and data.

        Returns:
            dict: A dictionary containing execution outcomes and results.
        """
        exec_results = {
            "generated_sql_execution_success": False, "generated_sql_error": None, "generated_sql_output": None,
            "ground_truth_sql_execution_success": False, "ground_truth_sql_error": None, "ground_truth_sql_output": None,
            "results_match": False,
            "db_setup_error": None
        }

        conn = None
        try:
            # 1. Setup In-Memory SQLite Database
            conn = sqlite3.connect(':memory:')
            cursor = conn.cursor()
            
            db_setup_statements = split_sql_statements(sql_context)
            if not db_setup_statements:
                exec_results["db_setup_error"] = "SQL context was empty or yielded no statements."
                if self.langfuse_manager and self.langfuse_manager.enabled and trace:
                    self.langfuse_manager.log_event(trace, name="exec_eval_db_setup_error", metadata={"error": exec_results["db_setup_error"]})
                return exec_results # Cannot proceed without DB setup

            for i, statement in enumerate(db_setup_statements):
                try:
                    cursor.execute(statement)
                except sqlite3.Error as e:
                    exec_results["db_setup_error"] = f"Error executing context statement #{i+1} ('{statement[:50]}...'): {e}"
                    if self.langfuse_manager and self.langfuse_manager.enabled and trace:
                        self.langfuse_manager.log_event(trace, name="exec_eval_db_setup_error", metadata={"error": exec_results["db_setup_error"], "statement_index": i, "statement_snippet": statement[:100]})
                    if conn: conn.close()
                    return exec_results # Critical setup failure
            
            conn.commit() # Commit schema changes
            if self.langfuse_manager and self.langfuse_manager.enabled and trace:
                 self.langfuse_manager.log_event(trace, name="exec_eval_db_setup_success", metadata={"statement_count": len(db_setup_statements)})


            # 2. Execute Generated SQL
            if generated_sql and isinstance(generated_sql, str) and generated_sql.strip():
                try:
                    cursor.execute(generated_sql)
                    raw_output_gen = cursor.fetchall()
                    exec_results["generated_sql_output"] = self._normalize_results(raw_output_gen)
                    exec_results["generated_sql_execution_success"] = True
                except sqlite3.Error as e:
                    exec_results["generated_sql_error"] = str(e)
            else:
                exec_results["generated_sql_error"] = "Generated SQL was empty or invalid."

            if self.langfuse_manager and self.langfuse_manager.enabled and trace:
                self.langfuse_manager.log_score(
                    trace, 
                    name="exec_eval_generated_sql_success", 
                    value=1 if exec_results["generated_sql_execution_success"] else 0,
                    comment=exec_results["generated_sql_error"] or "OK"
                )

            # 3. Execute Ground Truth SQL
            if ground_truth_sql and isinstance(ground_truth_sql, str) and ground_truth_sql.strip():
                try:
                    cursor.execute(ground_truth_sql)
                    raw_output_gt = cursor.fetchall()
                    exec_results["ground_truth_sql_output"] = self._normalize_results(raw_output_gt)
                    exec_results["ground_truth_sql_execution_success"] = True
                except sqlite3.Error as e:
                    exec_results["ground_truth_sql_error"] = str(e)
            else:
                exec_results["ground_truth_sql_error"] = "Ground truth SQL was empty or invalid."

            if self.langfuse_manager and self.langfuse_manager.enabled and trace:
                self.langfuse_manager.log_score(
                    trace, 
                    name="exec_eval_ground_truth_sql_success", 
                    value=1 if exec_results["ground_truth_sql_execution_success"] else 0,
                    comment=exec_results["ground_truth_sql_error"] or "OK"
                )

            # 4. Compare Results
            if exec_results["generated_sql_execution_success"] and exec_results["ground_truth_sql_execution_success"]:
                exec_results["results_match"] = (exec_results["generated_sql_output"] == exec_results["ground_truth_sql_output"])
            
            if self.langfuse_manager and self.langfuse_manager.enabled and trace:
                # Log match score only if both were expected to run successfully
                # If one failed, it's not a 'match' in the sense of output comparison
                # The individual success scores already capture execution failures.
                if exec_results["generated_sql_execution_success"] and exec_results["ground_truth_sql_execution_success"]:
                    self.langfuse_manager.log_score(trace, name="exec_eval_results_match", value=1 if exec_results["results_match"] else 0)
                elif not (exec_results["generated_sql_execution_success"] or exec_results["ground_truth_sql_execution_success"]): # both failed
                     self.langfuse_manager.log_score(trace, name="exec_eval_results_match", value=0, comment="Both queries failed to execute.")
                else: # one failed
                     self.langfuse_manager.log_score(trace, name="exec_eval_results_match", value=0, comment="One query failed, so no output match.")


        except Exception as e_outer: # Catch any unexpected errors during the whole process
            # This is a fallback for errors not caught by more specific handlers
            # (e.g., issues with sqlite3.connect, or logic errors in this script)
            error_msg = f"Outer exception in evaluate_single_item: {e_outer}"
            print(error_msg)
            if exec_results.get("db_setup_error") is None: # Don't overwrite specific DB setup error
                exec_results["db_setup_error"] = error_msg # General error if not already specific
            elif exec_results.get("generated_sql_error") is None and not exec_results.get("generated_sql_execution_success"):
                 exec_results["generated_sql_error"] = error_msg
            # Log a general error event to Langfuse if not already captured
            if self.langfuse_manager and self.langfuse_manager.enabled and trace:
                self.langfuse_manager.log_event(trace, name="exec_eval_critical_error", metadata={"error": str(e_outer)[:1000]})

        finally:
            # 5. Close Connection
            if conn:
                conn.close()
        
        return exec_results

```

The `ExecutionEvaluationModule` is implemented as specified.
Key points:
*   It initializes and stores the `langfuse_manager`.
*   `evaluate_single_item`:
    *   Sets up an in-memory SQLite database.
    *   Uses `split_sql_statements` (from `.utils`) to process `sql_context`.
    *   Executes generated and ground truth SQL, capturing results and errors.
    *   Uses `_normalize_results` (string conversion and sorting) for output comparison.
    *   Logs various scores and events to Langfuse (e.g., `exec_eval_generated_sql_success`, `exec_eval_results_match`, DB setup errors).
    *   Returns a dictionary with detailed execution outcomes.
*   `_normalize_results`: Converts all cell values to strings and sorts rows for order-insensitive comparison.

Next, I will update `sql_evaluation_library/__init__.py`.
