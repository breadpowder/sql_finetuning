# Setting Up a Database Environment for SQL Evaluation

## 1. Introduction

### Purpose
This document guides you through setting up a database environment to execute and verify the correctness of SQL queries generated by a Text-to-SQL model. This is a crucial step in execution-based evaluation, where you run the generated SQL against a populated database and compare the results with those from a ground truth query.

### Recommendation: SQLite
For simplicity, ease of use, and portability, **SQLite** is highly recommended, especially when working with dataset-driven evaluations like those involving the `gretelai/synthetic_text_to_sql` dataset. SQLite is a C-language library that implements a small, fast, self-contained, high-reliability, full-featured, SQL database engine. It's serverless and directly reads and writes to ordinary disk files.

## 2. Setting up SQLite with Python

### Python's `sqlite3` Module
Python has built-in support for SQLite through the `sqlite3` module. This means you typically **do not need to install any separate packages**.

**Verifying Availability:**
You can quickly verify its availability by trying to import it in a Python interpreter:
```python
import sqlite3
print(sqlite3.sqlite_version) # Prints the SQLite library version
print(sqlite3.version)      # Prints the sqlite3 module version
```
If these commands run without error, you're good to go.

### Creating a Database Connection

You can connect to an SQLite database that resides on disk or one that is held entirely in memory.

**On-Disk Database:**
This creates a file (e.g., `evaluation_item.db`) in your current directory. If the file doesn't exist, it will be created.
```python
import sqlite3

try:
    # Creates or opens 'evaluation_item.db'
    conn = sqlite3.connect("evaluation_item.db") 
    print("Successfully connected to on-disk database.")
    # ... proceed with database operations ...
except sqlite3.Error as e:
    print(f"Error connecting to SQLite database: {e}")
finally:
    if conn:
        conn.close()
```

**In-Memory Database:**
An in-memory database is faster as it avoids disk I/O and is automatically discarded when the connection is closed. This is ideal for temporary databases needed for isolated test case evaluations.
```python
import sqlite3

try:
    conn = sqlite3.connect(":memory:")
    print("Successfully connected to in-memory database.")
    # ... proceed with database operations ...
except sqlite3.Error as e:
    print(f"Error connecting to in-memory SQLite database: {e}")
finally:
    if conn:
        conn.close()
```

### Executing SQL Statements

Once connected, you need a `cursor` object to execute SQL statements.

**Executing `CREATE TABLE` and `INSERT INTO` (from `sql_context`):**
The `sql_context` usually contains `CREATE TABLE` statements and sometimes `INSERT INTO` statements to populate the schema.
```python
# Assuming 'conn' is an active SQLite connection
# And 'sql_context_string' contains one or more SQL statements (CREATE, INSERT)
# separated by semicolons, or as a list of statements.

sql_context_string = """
CREATE TABLE employees (
    id INTEGER PRIMARY KEY,
    name TEXT NOT NULL,
    department TEXT,
    salary REAL
);

INSERT INTO employees (id, name, department, salary) VALUES (1, 'Alice', 'Engineering', 75000);
INSERT INTO employees (id, name, department, salary) VALUES (2, 'Bob', 'Marketing', 60000);
"""

try:
    cursor = conn.cursor()
    
    # sqlite3 can execute multiple statements if they are in a single string using executescript
    # Note: Be cautious with executescript if the SQL string comes from untrusted sources.
    # For CREATE TABLE and INSERTs from a trusted context, it's usually fine.
    cursor.executescript(sql_context_string)
    print("Schema created and initial data inserted successfully.")
    
    # If sql_context is a list of individual statements:
    # for statement in list_of_sql_statements:
    #     cursor.execute(statement)
    # print("Schema created and initial data inserted successfully.")

    # Example for executemany (useful for many inserts with the same structure)
    # more_employees = [
    #     (3, 'Charlie', 'Engineering', 80000),
    #     (4, 'Diana', 'HR', 65000)
    # ]
    # cursor.executemany("INSERT INTO employees (id, name, department, salary) VALUES (?, ?, ?, ?)", more_employees)
    # print("Additional employees inserted using executemany.")

    conn.commit() # Commit changes if it's an on-disk database
    
except sqlite3.Error as e:
    print(f"Error executing schema/insert statements: {e}")
    if conn:
        conn.rollback() # Rollback changes on error
```

**Executing `SELECT` Queries (Generated or Ground Truth SQL):**
```python
# Assuming 'conn' is an active SQLite connection and schema is populated
# And 'generated_sql_query' is a string like "SELECT name FROM employees WHERE department = 'Engineering';"

generated_sql_query = "SELECT name, salary FROM employees WHERE department = 'Engineering' ORDER BY name;"

try:
    cursor = conn.cursor()
    cursor.execute(generated_sql_query)
    
    # Fetching Results
    # fetchall() fetches all rows as a list of tuples.
    results = cursor.fetchall() 
    print(f"Query results for '{generated_sql_query}': {results}")
    
    # If you expect only one row:
    # result_one = cursor.fetchone() 
    # print(f"Single query result: {result_one}")
    
    # You can also iterate over the cursor:
    # print("Query results (iterated):")
    # cursor.execute(generated_sql_query) # Re-execute if you already fetched all
    # for row in cursor:
    #     print(row)
        
except sqlite3.Error as e:
    print(f"Error executing SELECT query '{generated_sql_query}': {e}")
```

### Committing Changes and Closing Connection

*   **`connection.commit()`:** If you make any changes to the database (like `CREATE TABLE`, `INSERT`, `UPDATE`, `DELETE`) using an on-disk database, you **must** call `conn.commit()` for these changes to be saved to the database file. It's not needed for in-memory databases in terms of persistence (as they vanish when closed), but it's good practice if your code might switch between on-disk and in-memory.
*   **`connection.close()`:** Always close the connection when you're done with it to release resources. Use a `finally` block to ensure this happens even if errors occur.

### Error Handling
Wrap your database operations in `try...except sqlite3.Error as e:` blocks to catch and handle potential issues, such as SQL syntax errors, constraint violations, or connection problems.

```python
import sqlite3

def execute_query_in_db(db_path, setup_sql, query_sql):
    conn = None # Initialize conn to None
    results = None
    error = None
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        if setup_sql:
            cursor.executescript(setup_sql) # For CREATE TABLE, INSERTs
        
        cursor.execute(query_sql) # For the SELECT query
        results = cursor.fetchall()
        
        if db_path != ":memory:": # Commit if not in-memory and changes were made by setup_sql
            conn.commit() 
            
    except sqlite3.Error as e:
        print(f"Database error: {e}")
        error = str(e)
        if conn:
            conn.rollback() # Rollback any changes if an error occurs
    finally:
        if conn:
            conn.close()
    return results, error

# Example usage:
# setup_script = "CREATE TABLE test (id INT, name TEXT); INSERT INTO test VALUES (1, 'A');"
# query = "SELECT * FROM test;"
# results, error = execute_query_in_db(":memory:", setup_script, query)
# if error:
#     print(f"Execution failed: {error}")
# else:
#     print(f"Results: {results}")
```

## 3. Ensuring Evaluation Isolation

For reliable execution-based evaluation, it is **critical** to ensure that each test item (e.g., each (prompt, generated_sql, ground_truth_sql) tuple) is evaluated in a completely isolated database environment.

**Why Isolation is Important:**
*   **Prevents Data Contamination:** Data inserted or modified by one test case should not affect subsequent test cases.
*   **Ensures Schema Integrity:** Each test item might have a different `sql_context` defining its schema. Using a fresh database ensures the correct schema is active.
*   **Reproducibility:** Guarantees that running the same test item multiple times yields the same database state and thus comparable results.

**Recommended Approach: Database per Item**
Create a new database instance (preferably in-memory for speed, or a uniquely named temporary file if data needs inspection) for *each* item in your evaluation dataset.

**Conceptual Loop Structure:**
```python
import sqlite3
import json # Assuming your dataset items are in a JSONL file or similar

dataset_items = [ # Example dataset items
    {
        "id": "item1", 
        "sql_context": "CREATE TABLE users (id INT, name TEXT); INSERT INTO users VALUES (1, 'Alice');", 
        "generated_sql": "SELECT name FROM users WHERE id = 1;",
        "ground_truth_sql": "SELECT name FROM users WHERE id = 1;"
    },
    {
        "id": "item2", 
        "sql_context": "CREATE TABLE products (pid INT, stock INT); INSERT INTO products VALUES (101, 10);", 
        "generated_sql": "SELECT pid FROM products WHERE stock > 5;",
        "ground_truth_sql": "SELECT pid FROM products WHERE stock > 5;"
    }
    # ... more items
]

evaluation_outcomes = []

for item in dataset_items:
    item_id = item["id"]
    sql_context = item["sql_context"]
    generated_sql = item["generated_sql"]
    ground_truth_sql = item["ground_truth_sql"]
    
    conn = None
    print(f"\nProcessing item: {item_id}")
    try:
        # 1. Create a fresh in-memory database for each item
        conn = sqlite3.connect(":memory:")
        cursor = conn.cursor()
        
        # 2. Set up the schema using sql_context
        # Ensure sql_context is not None and is a string
        if sql_context and isinstance(sql_context, str):
            cursor.executescript(sql_context) 
            print(f"  DB setup for {item_id} successful.")
        else:
            print(f"  Skipping DB setup for {item_id} due to missing or invalid sql_context.")
            evaluation_outcomes.append({"item_id": item_id, "error": "Missing sql_context"})
            continue

        # 3. Execute Generated SQL
        generated_results = None
        try:
            cursor.execute(generated_sql)
            generated_results = cursor.fetchall()
            print(f"  Generated SQL results: {generated_results}")
        except sqlite3.Error as e_gen:
            print(f"  Error executing generated SQL for {item_id}: {e_gen}")
            generated_results = f"ERROR: {e_gen}"

        # 4. Execute Ground Truth SQL
        gt_results = None
        try:
            cursor.execute(ground_truth_sql)
            gt_results = cursor.fetchall()
            print(f"  Ground Truth SQL results: {gt_results}")
        except sqlite3.Error as e_gt:
            print(f"  Error executing ground truth SQL for {item_id}: {e_gt}")
            gt_results = f"ERROR: {e_gt}"
            
        # 5. Compare results (logic for comparison not shown here)
        # ... 
        
        evaluation_outcomes.append({
            "item_id": item_id,
            "generated_sql_output": generated_results,
            "ground_truth_sql_output": gt_results,
            # "is_match": compare_results(generated_results, gt_results) # Your comparison function
        })
        
    except sqlite3.Error as e_main:
        print(f"  Major error during processing for {item_id}: {e_main}")
        evaluation_outcomes.append({"item_id": item_id, "error": str(e_main)})
    finally:
        if conn:
            conn.close() # Discards the in-memory database

# Process evaluation_outcomes...
```

## 4. Alternative Database Systems (Brief Mention)

The `gretelai/synthetic_text_to_sql` dataset, or other similar datasets, might contain SQL queries that use dialects or features not fully supported by SQLite. Examples include:
*   Complex window functions with specific syntaxes.
*   Vendor-specific SQL functions or data types.
*   Stored procedures or other advanced database objects (though less common in such datasets).

If you encounter frequent SQLite errors due to unsupported SQL features, you might need to set up a more feature-rich database system that matches the dialect used in the dataset (often Spider dataset uses a generic SQL, but specific variants can appear). Common alternatives include:

*   **PostgreSQL:** A powerful, open-source object-relational database system.
*   **MySQL:** A widely used open-source relational database management system.

**Setup for these systems is more involved:**
*   You'll need to install the database server software itself.
*   Create users, databases, and manage permissions.
*   Refer to the official documentation for [PostgreSQL](https://www.postgresql.org/docs/) or [MySQL](https://dev.mysql.com/doc/) for installation and setup.

**Python Integration:**
The core logic of connecting, creating a cursor, executing queries, and fetching results remains conceptually similar, but you'll use different Python libraries:
*   **PostgreSQL:** `psycopg2` (or `psycopg` for newer versions)
    ```python
    # import psycopg2
    # conn = psycopg2.connect(database="mydb", user="user", password="password", host="localhost", port="5432")
    ```
*   **MySQL:** `mysql-connector-python`
    ```python
    # import mysql.connector
    # conn = mysql.connector.connect(user='user', password='password', host='localhost', database='mydb')
    ```
Connection parameters, SQL dialect for schema creation, and error handling details will also differ.

## 5. Next Steps

Once your database environment setup strategy is clear (SQLite per item, or a more complex DB if necessary), the next step is to implement the Python script that:
1.  Iterates through your evaluation dataset.
2.  For each item, sets up the isolated database using the `sql_context`.
3.  Executes both the generated SQL and the ground truth SQL.
4.  Fetches the results from both executions.
5.  Compares the results to determine if the generated SQL is correct.
6.  Logs all outcomes, errors, and results.

This forms the core of your execution-based Text-to-SQL evaluation pipeline.
```
